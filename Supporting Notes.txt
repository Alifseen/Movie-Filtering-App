Three types of recommendation systems filtering
popularity based = what majority of people like
collaborative = knowing what you like and what users like you like
content based = similar to content you are interested in.


Start by reviewing the data values
in movies csv we have the budget, genre as a list of dictionaries with id and names, homepage, id of movie, keywords as a list of dictionaries with id and tag name, language, title, overview description, popularity score, production companies as list of dictionary, release date, revenue, runtime, spoken languages as list of dictionaries, vote score, and vote count.

in credits csv share id column with movie csv, with cast and crew as a list of dictionaries

in ratings csv, we have user which also shares movie id with movies csv of the movie they reviewed and has rating given by the user and timestamp.

deepnote is a cloundbased jupyter webapp which has important packages already installed.
Create an account and workspace
create a new project
Each project can have several notebooks associated with the project.

You can write code in codeblocks like in jupyter notebook
You can add text by adding text blocks
You can upload files as well

load files
data = read_csv(csvanme)

data.head()



Two parts of this project 1. Devloping the model, 2 Connecting the model to the web app
Give heading calculate weighted rating
weighted average ensures that a movie that less people voted for is adjusted with movies with ratings by more users. So a movie that got 10/10 rating but has only 3 voters will be adjusted to be compard to movie with 7/10 rating from 3000 users
WR = (v / (v+m)) * R + (m + (v + m)) * C  (formula from IMDB)

v = number of votes
m = minimum number of votes requered to by considered
R = average rating of movie
C - average rating accross all movies

m = movies[vote count column].quantile(0.9)  0.9 is 90%. So this tells us the average maximum number of votes 90% of the movies got. We will set this as the minimum threshold.

c = movies[rating column].mean()   this gives us the average rating of all movies

now create a new column with weighted rating
movies.filtered["weighted avg column name"] = movies_filtered.apply(function name, axis=1) (1 is column, 0 is rows)

but define the function before creating a new column that applies the formula above in python
def function name(df, m=m, C=C)

R = df[rating column]
v = df[vote count column]
wr = type the formula above

to avoid division by zero error create filtered dataframe before this function that only includes movies with more votes than minimum threshold
movies_filtered = movies.copy().loc[movies[vote count column] >= m]

sort the df by the new column
movies_filtered.sort_values("weighted avg column naem", asceding =false).head(10)

To just see limited number of columns add the column names in double list [[]] before .head

you cna convert the df to dict to be able to serve it to a web app using .to_dict() after .head()





import pandas and load data
upload smaller version of movies csv file
read_csv(csv, sep=";")

compare descriptions

sklearn.feature_extraction.text import TfidVectorizer

tfidf = TfidVectorizer(stop_words="english")  ##instantiate, and tell it to recognize stop words

movies[descriptiuon column] = movies[description column].fillna("")   this replaces NA values with empty strings since we can only operate on string data type

tfidf_matrix = tfidf.fittransfrom(movies["overview"])  ## This creates a matrix with words in columns and movies in rows

to display the matrix, convert it to a numpy array, and view as dataframe
pd.DataFramre(tfidf.toarray())

Also define column names using another argument: columns=tfdif.get_feature_names()

This matrix has words as columns and rows as movies as said earlier, so each cell stores a number that represents 1. Term frequency: the repetition of the word inside that movies description and 2. Inverse Document: rarity of the word in other movies description. The higher the number, means the higher the rarity, meaning not existing in other movie databases and is more unique to that movie. This is usefult for creating a matrix of cooeffecients to get the overlap created by least rare words

You can get the number of words in the matrix using tfidf_matrix.shape to get the number of columns.








sklearn.metrics.pairwise linear_kernel  this is an algorithms
similarity_matrix = linear_kernal(matrix 1, matrix 2)  We will use the same matrix in both since we are comparing within the matrix, not two matrices

this matrix is a list of list with the same number of columns as rows, comparing each movie with all other movies and returning a coefficient of similarty for it. the higher the coefficient, the more the similarity. 1 means identical, so same movie.

To make this more accurate, we can join the keywords/tags and genre columns with overview column and do the same process on that column.







define a function that takes in as argument a movie title and 2nd argument number of movies and returns that many movies similar to the movie title

after storing the title string, set the list in ascending order to see most similar to least, excluding 1
sorted(matrix[index number of movie title], reverse=True)

We need a way to convert the movie title to the list index to be able to sort the correct list from the matrix
index_number = dataframename.loc[dataframename["column name with titles"]==movie title variable.index[0]

Similarly we need to be able to identify other movies in the matrix as well. We can do that by locking in their position in the matrix list before sorting it by creating a copy of list and using enumaerate to hard code index to each value. This way even if we sort the list, if movie at position 3 had the highest coefficient, it would still have the hard coded value in column showing positing 3 even if the list is sorted and its index number changes.
copy_list = list(enumerate(matrix[index_number]))


To sort the list by the coefficient we can use lambda function (which is a one liner function) to assign it as key
sorted(copy_list, key = lambda x: x[1], revers=True)   x[0] is the hard coded index number
be sure to reassign the sorted list to the copy_list variable to reatin changes


next we extract the top 3 most similar movies and store in a new variable using list comprehension
similar_movie_indices =  [item[0] for item in copy_list[1:4]
we slice the list to exclude the movie itself (coefficient of 1) so [1:] and since we only want top 3, we end with[1:4], so index position 1,2,3, not 0 or after 3

next, get the title using these indices
dataframename[column name with title].iloc[similar moview indices]
This returns a dataframe, you can convert it to a list

add all the lines of code above in the def function and return the list. Be sure to replace the slice with number of movies variable + 1 to slice dynamically

call the function with a movie title and index
simalar_movies(title, number)

Replace the short movie csv with main movie csv